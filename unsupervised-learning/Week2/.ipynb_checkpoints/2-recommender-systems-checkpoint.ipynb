{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cbdf4b2-b21c-42b5-915d-dc6065f2d291",
   "metadata": {},
   "source": [
    "**Mean normalisation**  \n",
    "\n",
    "If no mean normalisation:\n",
    " - parameters w,b find to be 0\n",
    " - when calculate x, w.x+b = 0 so x=0\n",
    "\n",
    "Mean normalisation helps:\n",
    " - compute average of feature, $\\mu$\n",
    " - subtract mean rating from each value\n",
    " - $x-\\mu$\n",
    " - for user j:\n",
    "   - $w^{(j)} \\cdot x^{(i)} + b^{(j)} + \\mu_i$\n",
    " - Can normalise rows or columns depending on application/situation\n",
    "\n",
    "\n",
    "Will cause new users to start at average rather than 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb1684e-b407-4ac4-a4c3-9984419bf395",
   "metadata": {},
   "source": [
    "**Tensorflow implementation**  \n",
    "\n",
    "Cost function: $J = (f(x)-y)^2$  \n",
    "\n",
    "Gradient descent repeats until convergence  \n",
    "If  you have a cost function, tensorflow can differentate it  \n",
    "Auto Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f64b5753-b041-401b-9647-4bd6e37b3b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "w = tf.Variable(3.0) #initialise variable that we want to optimise (w in this case)\n",
    "x = 1.0\n",
    "y = 1.0 # target value\n",
    "alpha = 0.01\n",
    "\n",
    "iterations = 30\n",
    "for i in range(iterations):\n",
    "    # Use tf Gradient tape to record steps used to \n",
    "    # compute cost J, to enable auto differentiation\n",
    "    with tf.GradientTape() as tape: # saved sequence of operations in tape.gradient\n",
    "        fwb = w*x\n",
    "        costJ = (fwb-y)**2\n",
    "\n",
    "    # U se gradient tape to calc gradients of cost\n",
    "    # w.r.t. the parameter w\n",
    "    [dJdw] = tape.gradient(costJ, [w])\n",
    "\n",
    "    # Run one stop of gradient descent by updating \n",
    "    # value of w to reduce cost\n",
    "    w.assign_add(-alpha * dJdw) # tf.variables require special func to modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e103139c-e9dc-4cad-9182-12f957b21979",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (336238336.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    cost_value = cofiCostFuncV(X, W, b, Ynorm, R, num_users, num_movies, lambda)\u001b[0m\n\u001b[0m                                                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Can do it with adam optimizer\n",
    "# Movie rating example:\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 1.e-1)\n",
    "\n",
    "iterations = 200\n",
    "\n",
    "for i in range(iterations):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost_value = cofiCostFuncV(X, W, b, Ynorm, R, num_users, num_movies, lambda)\n",
    "\n",
    "\n",
    "    # Use gradient tape to auto retrieve grads of trainable variables w.r.t. loss\n",
    "    grads = tape.gradient(cost_value, [X,W,b])\n",
    "\n",
    "    # Run one step of grad descent by updating value of variables to minimise loss\n",
    "    optimizer.apply_gradients(zip(grads, [X,W,b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6181a635-7947-46cb-b316-5531885ee26e",
   "metadata": {},
   "source": [
    "**Finding related items**  \n",
    "\n",
    "Find other items related to i:\n",
    " - Find item k with $x^{(k)}$ similar to $x^{(i)}$\n",
    " - To do this:\n",
    "   - $\\sum_{l=1}^n (x^{(k)} - x^{(i)})^2$\n",
    "   - $||x^{(k)} - x^{(i)}||^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5355e9a0-ee38-4819-af4f-273c47412f98",
   "metadata": {},
   "source": [
    "**Limitations to collaborative filtering**  \n",
    "\n",
    "Not good at cold start problem:\n",
    " - Rank new items that few users have rated?\n",
    " - Show something reasonable to new users who have rated very few items?\n",
    " - Called cold start problem\n",
    " - Might not be accurate in these scenarios\n",
    "\n",
    "Doesn't give a natural way to use side information about items or users:\n",
    " - Item: Genre, movie stars, studio\n",
    " - User: Demographics, preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e3b31c-2b85-4293-bb1d-fe6940317a85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
